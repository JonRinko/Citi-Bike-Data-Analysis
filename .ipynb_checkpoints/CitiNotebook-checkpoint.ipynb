{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect Postgres db \n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the username and pw is 'postgres'\n",
    "engine = create_engine(\"postgresql://postgres:postgres@localhost:5432/CitiBike\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the conn with simple query and view tables at the same time\n",
    "tables = pd.read_sql(\"SELECT * from information_schema.tables WHERE table_catalog = 'CitiBike' AND table_schema = 'public'\", conn)\n",
    "tables.head(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Notice the tables have poor naming choices and NO PK: instead of using a sortable names like 01_2018, I went with january_2018 and so on... don't make these mistakes! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the new table to combine the data in pgAdmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE TABLE cumulative (\n",
    "\tid serial primary key,\n",
    "\ttripduration integer NOT NULL, \n",
    "\tstarttime date, stoptime date, \n",
    "\tstart_station_id varchar(20), \n",
    "\tstart_station_name varchar, \n",
    "\tstart_station_latitude float, start_station_longitude float,\n",
    "\tend_station_id varchar(20), end_station_name varchar, \n",
    "\tend_station_latitude float, end_station_longitude float, \n",
    "\tbikeid varchar(20),\n",
    "\tusertype varchar(20), birth_year varchar(4), gender integer\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were smarter than I was, and remebered to add the PK to your initial tables, then all you need to do is copy a table setup into the new table instead of typing all the columns as in the above block.\n",
    "#### Here is the code to do just that: \n",
    "SELECT * FROM september_2019; --choose any existing table to copy the format\n",
    "\n",
    "CREATE TABLE cumulative AS TABLE september_2019 WITH NO DATA;\n",
    "\n",
    "SELECT * FROM cumulative;  -- test that we have the matching empty table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add tables into cumulative table\n",
    "-- insert data from direct import \n",
    "\n",
    "INSERT INTO public.cumulative( tripduration, starttime, stoptime, start_station_id, start_station_name, start_station_latitude, start_station_longitude, end_station_id, end_station_name, end_station_latitude, end_station_longitude, bikeid, usertype, birth_year, gender) \n",
    "(SELECT * FROM april_2018);\n",
    "\n",
    "-- and test this out with \n",
    "\n",
    "SELECT * FROM cumulative LIMIT 10;\n",
    "\n",
    "#### repeat this statement, changing the table name, for the remaining 22 tables:\n",
    "\n",
    "INSERT INTO public.cumulative( tripduration, starttime, stoptime, start_station_id, start_station_name, start_station_latitude, start_station_longitude, end_station_id, end_station_name, end_station_latitude, end_station_longitude, bikeid, usertype, birth_year, gender) \n",
    "(SELECT * FROM april_2019);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are ready to query the combined table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take a look at the data\n",
    "station_count = pd.read_sql(\"SELECT COUNT(DISTINCT start_station_name) FROM cumulative\", conn)\n",
    "station_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to try to remove any unneccesary data from the table to speed up our queries and prevent tableau from crashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's test is there are candidates to remove \n",
    "\n",
    "Since the [CitiBike pricing](https://www.citibikenyc.com/pricing) states the max time you can have a bike is 45 minutes, lets looks there first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmaxduration = pd.read_sql(\"SELECT tripduration FROM cumulative WHERE tripduration > (45*60) ORDER BY tripduration DESC LIMIT 50\",conn)\n",
    "testmaxduration.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see there are plenty of trips that are over the 45 min mark, which could mean the bikes failed to properly dock, they were stolen or something else. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Im a day there are \n",
    "h = 24 # 24 hours per day\n",
    "m = 60 # 60 min per hour\n",
    "s = 60 # 60 sec per min\n",
    "d = h*m*s\n",
    "print(f'There are {d} seconds per day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I'd like to take a look at some of the data for trips greater than 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmaxduration = pd.read_sql(\"SELECT tripduration, starttime, start_station_id, start_station_name, bikeid, usertype, birth_year, gender FROM cumulative WHERE tripduration > (86400) ORDER BY tripduration DESC LIMIT 200\",conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmd = pd.DataFrame(testmaxduration)\n",
    "tmd.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding in end_station and a few other columns \n",
    "testmax2 = pd.read_sql(\"SELECT tripduration, starttime, start_station_id, end_station_id, start_station_name, end_station_name, bikeid, usertype, birth_year, gender FROM cumulative WHERE tripduration > (86400) order BY tripduration DESC LIMIT 50\",conn)\n",
    "testmax2.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does **NOT** appear to be a relation between extended trip duration and any other factors so **I am going to remove any data with trip duration > 1 day and less than 90 seconds.** The data has already excluded trips less than 60 seconds, but I am going to be more generous and not qualify a trip as being less than 90 seconds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Warning:</b> The following statement took <strong>5 min and 30 sec</strong> to run in postgres, so this may be a good time to go make a sandwich or actually go for a bike ride.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img width=\"320\" height=\"320\" src=\"Images/newbikes.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approximate_row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19024368.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   approximate_row_count\n",
       "0             19024368.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now I want to see if this is a potential candidate for uploading to Tableau by getting an approximate count\n",
    "# The approximate_row_count happens to be MUCH FASTER than simply using COUNT\n",
    "\n",
    "nb_count = pd.read_sql(\"SELECT reltuples AS approximate_row_count FROM pg_class WHERE relname = 'newbikes'\",conn)\n",
    "nb_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19 million rows! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approximate_row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19147684.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   approximate_row_count\n",
       "0             19147684.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of curiosity, what was the initial aprox count? \n",
    "\n",
    "cumul_ct = pd.read_sql(\"SELECT reltuples AS approximate_row_count FROM pg_class WHERE relname = 'cumulative'\",conn)\n",
    "cumul_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approximate_row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>123316.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   approximate_row_count\n",
       "0               123316.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_ct - nb_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If only there was a way to make smaller and more meaningful tables..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"300\" height=\"300\" src=\"Images/death-brainstorm.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Ideas: make smaller tables grouping and joining trips by:\n",
    "* gender, age\n",
    "* usertype\n",
    "* quarters\n",
    "* most active stations\n",
    "* aggregate functions\n",
    "* top n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2483550"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we divide this data by quarters we should get about 19,024,000/7.66 rows per quarter or \n",
    "int(19024000/7.66) #since we are missing december 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But since we know the max rows for an excel file is about 1,048,000, and we don't want to use files that large anyway, \n",
    "we will need to make smaller files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to pgadmin\n",
    "We are going to create a table of the starting stations and the count of trips each station recorded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT COUNT(id), start_station_name  \n",
    "FROM newbikes  \n",
    "GROUP BY start_station_name  \n",
    "ORDER BY COUNT(id) DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pgadmin, we can export this table to a csv to load into Tableau\n",
    "(we can also create a df in python here and write to csv)\n",
    "\n",
    "<img width=\"400\" height=\"300\" src=\"https://github.com/JonRinko/Citi-Bike-Data-Analysis/blob/master/Images/start_stations.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to map this in tableau, lets inner join this with the station long and lats in a new table \n",
    "\n",
    "<img width=\"400\" height=\"300\" src=\"https://github.com/JonRinko/Citi-Bike-Data-Analysis/blob/master/Images/start-station-join-coords.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From just one csv, we can create 3 visuals and a [Dashboard](https://public.tableau.com/profile/jon4546#!/vizhome/CitiBikeStartStationTripCountsDashboard/Dashboard1?publish=yes) in Tableau! \n",
    "<img width=\"700\" height=\"500\" src=\"https://github.com/JonRinko/Citi-Bike-Data-Analysis/blob/master/Images/dash1.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add vid of dashboard and link "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: \n",
    "Use Linear Regression to Forecast December's Data \n",
    "<br>Use same Linear Regression to Forecast November's Data and compare to actual  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
